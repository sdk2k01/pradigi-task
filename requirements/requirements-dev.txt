#
# This file is autogenerated by pip-compile with Python 3.12
# by the following command:
#
#    pip-compile --extra=dev --output-file=requirements/requirements-dev.txt pyproject.toml
#
aiohappyeyeballs==2.3.4
    # via aiohttp
aiohttp==3.10.0
    # via
    #   llama-index-core
    #   llama-index-legacy
    #   llama-index-readers-web
aiosignal==1.3.1
    # via aiohttp
annotated-types==0.7.0
    # via pydantic
anyio==4.4.0
    # via
    #   httpx
    #   openai
attrs==23.2.0
    # via
    #   aiohttp
    #   outcome
    #   trio
beautifulsoup4==4.12.3
    # via
    #   feedfinder2
    #   llama-index-readers-file
    #   llama-index-readers-web
    #   newspaper3k
black==24.4.2
    # via pradigi-task (pyproject.toml)
certifi==2024.7.4
    # via
    #   httpcore
    #   httpx
    #   requests
    #   selenium
charset-normalizer==3.3.2
    # via requests
chromedriver-autoinstaller==0.6.4
    # via llama-index-readers-web
click==8.1.7
    # via
    #   black
    #   nltk
coloredlogs==15.0.1
    # via onnxruntime
cssselect==1.2.0
    # via newspaper3k
dataclasses-json==0.6.7
    # via
    #   llama-index-core
    #   llama-index-legacy
deprecated==1.2.14
    # via
    #   llama-index-core
    #   llama-index-legacy
dirtyjson==1.0.8
    # via
    #   llama-index-core
    #   llama-index-legacy
distro==1.9.0
    # via openai
fastembed==0.2.7
    # via
    #   llama-index-embeddings-fastembed
    #   qdrant-client
feedfinder2==0.0.4
    # via newspaper3k
feedparser==6.0.11
    # via newspaper3k
filelock==3.15.4
    # via
    #   huggingface-hub
    #   tldextract
flatbuffers==24.3.25
    # via onnxruntime
frozenlist==1.4.1
    # via
    #   aiohttp
    #   aiosignal
fsspec==2024.6.1
    # via
    #   huggingface-hub
    #   llama-index-core
    #   llama-index-legacy
greenlet==3.0.3
    # via
    #   playwright
    #   sqlalchemy
grpcio==1.65.2
    # via
    #   grpcio-tools
    #   llama-index-vector-stores-qdrant
    #   qdrant-client
grpcio-tools==1.65.2
    # via qdrant-client
h11==0.14.0
    # via
    #   httpcore
    #   wsproto
h2==4.1.0
    # via httpx
hpack==4.0.0
    # via h2
html2text==2024.2.26
    # via llama-index-readers-web
httpcore==1.0.5
    # via httpx
httpx[http2]==0.27.0
    # via
    #   llama-cloud
    #   llama-index-core
    #   llama-index-legacy
    #   mistralai
    #   openai
    #   qdrant-client
huggingface-hub==0.20.3
    # via
    #   fastembed
    #   tokenizers
humanfriendly==10.0
    # via coloredlogs
hyperframe==6.0.1
    # via h2
idna==3.7
    # via
    #   anyio
    #   httpx
    #   requests
    #   tldextract
    #   trio
    #   yarl
jieba3k==0.35.1
    # via newspaper3k
joblib==1.4.2
    # via nltk
llama-cloud==0.0.11
    # via llama-index-indices-managed-llama-cloud
llama-index==0.10.58
    # via pradigi-task (pyproject.toml)
llama-index-agent-openai==0.2.9
    # via
    #   llama-index
    #   llama-index-program-openai
llama-index-cli==0.1.13
    # via llama-index
llama-index-core==0.10.58
    # via
    #   llama-index
    #   llama-index-agent-openai
    #   llama-index-cli
    #   llama-index-embeddings-fastembed
    #   llama-index-embeddings-openai
    #   llama-index-indices-managed-llama-cloud
    #   llama-index-llms-mistralai
    #   llama-index-llms-openai
    #   llama-index-multi-modal-llms-openai
    #   llama-index-program-openai
    #   llama-index-question-gen-openai
    #   llama-index-readers-file
    #   llama-index-readers-llama-parse
    #   llama-index-readers-web
    #   llama-index-vector-stores-qdrant
    #   llama-parse
llama-index-embeddings-fastembed==0.1.7
    # via pradigi-task (pyproject.toml)
llama-index-embeddings-openai==0.1.11
    # via
    #   llama-index
    #   llama-index-cli
llama-index-indices-managed-llama-cloud==0.2.7
    # via llama-index
llama-index-legacy==0.9.48
    # via llama-index
llama-index-llms-mistralai==0.1.19
    # via pradigi-task (pyproject.toml)
llama-index-llms-openai==0.1.27
    # via
    #   llama-index
    #   llama-index-agent-openai
    #   llama-index-cli
    #   llama-index-multi-modal-llms-openai
    #   llama-index-program-openai
    #   llama-index-question-gen-openai
llama-index-multi-modal-llms-openai==0.1.8
    # via llama-index
llama-index-program-openai==0.1.7
    # via
    #   llama-index
    #   llama-index-question-gen-openai
llama-index-question-gen-openai==0.1.3
    # via llama-index
llama-index-readers-file==0.1.32
    # via llama-index
llama-index-readers-llama-parse==0.1.6
    # via llama-index
llama-index-readers-web==0.1.23
    # via pradigi-task (pyproject.toml)
llama-index-vector-stores-qdrant==0.2.14
    # via pradigi-task (pyproject.toml)
llama-parse==0.4.9
    # via llama-index-readers-llama-parse
loguru==0.7.2
    # via fastembed
lxml==5.2.2
    # via newspaper3k
marshmallow==3.21.3
    # via dataclasses-json
mistralai==0.4.2
    # via llama-index-llms-mistralai
mpmath==1.3.0
    # via sympy
multidict==6.0.5
    # via
    #   aiohttp
    #   yarl
mypy-extensions==1.0.0
    # via
    #   black
    #   typing-inspect
nest-asyncio==1.6.0
    # via
    #   llama-index-core
    #   llama-index-legacy
networkx==3.3
    # via
    #   llama-index-core
    #   llama-index-legacy
newspaper3k==0.2.8
    # via llama-index-readers-web
nltk==3.8.1
    # via
    #   llama-index-core
    #   llama-index-legacy
    #   newspaper3k
numpy==1.26.4
    # via
    #   fastembed
    #   llama-index-core
    #   llama-index-legacy
    #   onnx
    #   onnxruntime
    #   pandas
    #   qdrant-client
onnx==1.16.1
    # via fastembed
onnxruntime==1.18.1
    # via fastembed
openai==1.37.1
    # via
    #   llama-index-agent-openai
    #   llama-index-core
    #   llama-index-legacy
orjson==3.10.6
    # via mistralai
outcome==1.3.0.post0
    # via trio
packaging==24.1
    # via
    #   black
    #   chromedriver-autoinstaller
    #   huggingface-hub
    #   marshmallow
    #   onnxruntime
pandas==2.2.2
    # via
    #   llama-index-core
    #   llama-index-legacy
pathspec==0.12.1
    # via black
pillow==10.4.0
    # via
    #   llama-index-core
    #   newspaper3k
platformdirs==4.2.2
    # via black
playwright==1.45.1
    # via llama-index-readers-web
portalocker==2.10.1
    # via qdrant-client
protobuf==5.27.3
    # via
    #   grpcio-tools
    #   onnx
    #   onnxruntime
pydantic==2.8.2
    # via
    #   llama-cloud
    #   mistralai
    #   openai
    #   qdrant-client
pydantic-core==2.20.1
    # via pydantic
pyee==11.1.0
    # via playwright
pypdf==4.3.1
    # via llama-index-readers-file
pysocks==1.7.1
    # via urllib3
python-dateutil==2.9.0.post0
    # via
    #   newspaper3k
    #   pandas
python-dotenv==1.0.1
    # via pradigi-task (pyproject.toml)
pytz==2024.1
    # via pandas
pyyaml==6.0.1
    # via
    #   huggingface-hub
    #   llama-index-core
    #   newspaper3k
qdrant-client[fastembed]==1.10.1
    # via
    #   llama-index-vector-stores-qdrant
    #   pradigi-task (pyproject.toml)
regex==2024.7.24
    # via
    #   nltk
    #   tiktoken
requests==2.32.3
    # via
    #   fastembed
    #   feedfinder2
    #   huggingface-hub
    #   llama-index-core
    #   llama-index-legacy
    #   llama-index-readers-web
    #   newspaper3k
    #   requests-file
    #   spider-client
    #   tiktoken
    #   tldextract
requests-file==2.1.0
    # via tldextract
ruff==0.5.5
    # via pradigi-task (pyproject.toml)
selenium==4.23.1
    # via llama-index-readers-web
sgmllib3k==1.0.0
    # via feedparser
six==1.16.0
    # via
    #   feedfinder2
    #   python-dateutil
sniffio==1.3.1
    # via
    #   anyio
    #   httpx
    #   openai
    #   trio
sortedcontainers==2.4.0
    # via trio
soupsieve==2.5
    # via beautifulsoup4
spider-client==0.0.27
    # via llama-index-readers-web
sqlalchemy[asyncio]==2.0.31
    # via
    #   llama-index-core
    #   llama-index-legacy
    #   sqlalchemy
striprtf==0.0.26
    # via llama-index-readers-file
sympy==1.13.1
    # via onnxruntime
tenacity==8.5.0
    # via
    #   llama-index-core
    #   llama-index-legacy
tiktoken==0.7.0
    # via
    #   llama-index-core
    #   llama-index-legacy
tinysegmenter==0.3
    # via newspaper3k
tldextract==5.1.2
    # via newspaper3k
tokenizers==0.15.2
    # via fastembed
tqdm==4.66.4
    # via
    #   fastembed
    #   huggingface-hub
    #   llama-index-core
    #   nltk
    #   openai
trio==0.26.0
    # via
    #   selenium
    #   trio-websocket
trio-websocket==0.11.1
    # via selenium
typing-extensions==4.12.2
    # via
    #   huggingface-hub
    #   llama-index-core
    #   llama-index-legacy
    #   openai
    #   pydantic
    #   pydantic-core
    #   pyee
    #   selenium
    #   sqlalchemy
    #   typing-inspect
typing-inspect==0.9.0
    # via
    #   dataclasses-json
    #   llama-index-core
    #   llama-index-legacy
tzdata==2024.1
    # via pandas
urllib3[socks]==2.2.2
    # via
    #   llama-index-readers-web
    #   qdrant-client
    #   requests
    #   selenium
websocket-client==1.8.0
    # via selenium
wrapt==1.16.0
    # via
    #   deprecated
    #   llama-index-core
wsproto==1.2.0
    # via trio-websocket
yarl==1.9.4
    # via aiohttp

# The following packages are considered to be unsafe in a requirements file:
# setuptools
